example_1:
    question: Find the number of trips for route_id '25490' on a typical Friday
    answer: |
        To solve the problem of finding the number of trips for `route_id '25490'` on friday, we can follow these steps:

        1. Identify the service_ids that are applicable by checking the calendar DataFrame for Friday.
        2. Filter the trips DataFrame to include those that correspond to `route_id '25490'` and fall under the previously identified friday service_ids.
        3. Count the resulting trips.

        Here's the Python code to implement this:

        ```python
        # Get friday service_ids
        friday_services = feed.calendar[(feed.calendar['friday'] == 1)]['service_id']

        # Filter trips for route_id '25490' and friday services
        friday_trips = feed.trips[(feed.trips['route_id'] == '25490') & 
                                    (feed.trips['service_id'].isin(friday_services))]

        # Count the trips
        trip_count = friday_trips.shape[0]

        result = {
            'answer': trip_count,
            'additional_info': "This count includes all trips scheduled for fridays according to the calendar, excluding any exceptions in calendar_dates."
        }
        # Note: No plot or map for this example
        ```

example_2:
    question: Calculate the average trip duration for route_id '25490'
    answer: |
        To calculate the average trip duration for route '25490', we need to consider a few key points:

        1. We're dealing with GTFS data, which typically includes information about trips, routes, and stop times.
        2. We need to focus only on the trips associated with route '25490'.
        3. For each trip, we need to find its duration by calculating the difference between its last and first stop times.
        4. Once we have all trip durations, we can calculate their average.

        Additionally, to provide more insight:

        5. We'll count how many trips we're basing our calculation on for context.
        6. A histogram of trip durations could help visualize the distribution, showing if most trips are clustered around the average or if there's significant variation.

        This approach gives us not just the average duration, but also a fuller picture of trip durations for this route, which could be useful for further analysis or decision-making.

        Here's the code to implement this analysis:

        ```python
        # Filter stop_times for route_id '25490'
        route_25490_trips = feed.trips[feed.trips['route_id'] == '25490']['trip_id']
        route_25490_stop_times = feed.stop_times[feed.stop_times['trip_id'].isin(route_25490_trips)]

        # Calculate trip durations
        trip_durations = route_25490_stop_times.groupby('trip_id').agg({
            'arrival_time': lambda x: x.max() - x.min()
        })

        # Calculate average duration
        avg_duration = trip_durations['arrival_time'].mean()

        # Create the plot
        fig = px.histogram(trip_durations.reset_index(), x='arrival_time', 
                            title='Distribution of Trip Durations for Route 25490')

        result = {
            'answer': avg_duration,  # This is a timedelta object
            'additional_info': f"This calculation is based on {len(trip_durations)} trips.",
            'plot': fig  # This is a plotly Figure object
        }
        # Note: The plot shows the distribution of trip durations for route_id '25490'
        ```

example_3:
    question: Calculate the headway for a given route
    answer: |
        To calculate the headway for a given route, we need to consider several factors:

        1. Headway is typically defined as the time interval between vehicles arriving at a stop.
        2. We'll focus on a specific route and direction, as headways can vary depending on these factors.
        3. For simplicity, we'll calculate headways at the first stop of each trip, though they might vary along the route.
        4. We need to sort trips by their arrival time to calculate time differences between consecutive arrivals.
        5. It's important to consider that headways might vary throughout the day, so we'll prepare data for visualization.
        6. We'll calculate an overall average headway, but also provide a boxplot to show how headways distribute across different hours of the day.

        This approach will give us both a single metric (average headway) and a more nuanced view of how service frequency changes throughout the day. This information can be crucial for service planning and passenger information.

        Here's the code to implement this analysis:

        ```python
        # Assume the route_id and direction_id we're interested in
        route_id = feed.routes.route_id.sample(n=1).values[0]
        direction_id = feed.trips[feed.trips.route_id == route_id].direction_id.sample(n=1).values[0]

        # Get all trips for the specified route
        route_trips = feed.trips[(feed.trips['route_id'] == route_id) & (feed.trips['direction_id'] == direction_id)]

        if route_trips.empty:
            result =  {"answer": None, "additional_info": f"No trips found for route {route_id}"}


        # Get the first stop for each trip
        first_stop_id = feed.stop_times[feed.stop_times['trip_id'].isin(route_trips['trip_id']) & 
                                        (feed.stop_times['stop_sequence'] == 1)]['stop_id'].iloc[0]
        first_stops = feed.stop_times[feed.stop_times['trip_id'].isin(route_trips['trip_id']) & 
                                        (feed.stop_times['stop_sequence'] == 1)]

        first_stops = first_stops.sort_values('arrival_time')
        first_stops['headway_minutes'] = first_stops['arrival_time'].diff() /60
        first_stops['arrival_hour'] = first_stops['arrival_time']/3600

        # Calculate overall average headway
        overall_avg_headway = first_stops['headway_minutes'].mean()

        # Create a plot
        fig = px.box(first_stops, x='arrival_hour', y='headway_minutes', 
                        title=f'Headways Distribution for Route {route_id} Direction {direction_id} (at First Stop {first_stop_id})',)
        fig.update_layout(
            xaxis_title="Hour of the day",
            yaxis_title="Headway (minutes)",
        )

        result = {
            'answer': overall_avg_headway,
            'additional_info': (f"Average headway calculated for route {route_id} direction {direction_id} at first stop {first_stop_id}"
                                f"Headways vary by service_id: {service_headways}"),
            'plot': fig
        }
        # Note headways might vary for stops along the route, we calculate for the first stop only
        ```

example_4:
    question: Find the longest route in the GTFS feed
    answer: |
        To find the longest route in the GTFS feed, we need to consider the following:

        1. Routes are defined by shapes in GTFS, and each shape has a series of points with distances.
        2. We need to calculate the total distance for each shape by finding the maximum distance traveled.
        3. Shapes are associated with trips, and trips are associated with routes. We'll need to link these together.
        4. Some routes might have multiple shapes, so we'll need to find the maximum distance for each route.
        5. Finally, we'll identify the route with the greatest maximum distance as the longest route.

        This approach allows us to account for complex route structures and ensures we're finding the truly longest route in the network. We'll also gather additional information about the longest route to provide context.

        Here's the code to implement this analysis:

        ```python
        # Group shapes by shape_id and calculate total distance for each shape
        shape_distances = feed.shapes.groupby('shape_id').agg({'shape_dist_traveled': 'max'}).reset_index()

        # Merge shape distances with trips to get route_id for each shape
        route_distances = pd.merge(feed.trips[['route_id', 'shape_id']], shape_distances, on='shape_id', how='left')

        # Group by route_id and find the maximum distance for each route
        route_max_distances = route_distances.groupby('route_id').agg({'shape_dist_traveled': 'max'}).reset_index()

        # Get the longest route
        longest_route = route_max_distances.loc[route_max_distances['shape_dist_traveled'].idxmax()]
        longest_route_info = feed.routes[feed.routes['route_id'] == longest_route['route_id']].iloc[0]

        result = {
            'answer': {
                'route_id': longest_route['route_id'],
                'route_name': longest_route_info['route_long_name'],
                'length': longest_route['shape_dist_traveled']
            },
            'additional_info': longest_route_info,
        }
        ```

        This code calculates the longest route and provides detailed information about it, including its ID, name, and length. The `additional_info` field contains all available information about the route from the GTFS feed.

example_5:
    question: Identify the date when a specific route had the fewest trips in the GTFS feed.
    answer: |
        Our approach will be:
        - Identify all trips associated with the specified route.
        - Determine the valid date range from the feed info.
        - For each date, calculate the active services based on the calendar and exceptions.
        - Count the trips for each date based on the active services.
        - Find the date with the minimum number of trips (excluding dates with no service).
        - Create a plot to visualize the trip counts over time.

        This method ensures we accurately account for all service patterns and provide a comprehensive view of how the route's service frequency changes over time.

        Here's the code to implement this analysis:

        ```python
        # Specify the route_id we're interested in
        route_id = "25491"

        # Get trips for the specified route
        route_trips = feed.trips[feed.trips["route_id"] == route_id]
        valid_services = set(route_trips.service_id)

        # Count trips per service
        service_trip_count = route_trips.groupby("service_id").size()

        # Get date range
        start_date = feed.feed_info["feed_start_date"].iloc[0]
        end_date = feed.feed_info["feed_end_date"].iloc[0]
        date_range = pd.date_range(start=start_date, end=end_date)
        date_range = [date.date() for date in date_range]

        date_trip_count = {}
        for date in date_range:
            day_of_week = date.strftime("%A").lower()
            
            # Get active services for the date
            active_services = set(feed.calendar[
                (feed.calendar["start_date"] <= date) &
                (feed.calendar["end_date"] >= date) &
                (feed.calendar[day_of_week] == 1)
            ].service_id)
            
            # Apply exceptions
            exceptions = feed.calendar_dates[feed.calendar_dates["date"] == date]
            for _, exception in exceptions.iterrows():
                if exception["exception_type"] == 1:
                    active_services.add(exception["service_id"])
                elif exception["exception_type"] == 2:
                    active_services.discard(exception["service_id"])
            
            # Count trips for active services that are valid for this route
            trips = sum(service_trip_count.get(service, 0) 
                        for service in (active_services & valid_services))
            
            date_trip_count[date] = trips

        # Convert the dictionary to a DataFrame for easier analysis
        trip_count_df = pd.DataFrame.from_dict(date_trip_count, orient='index', columns=['trip_count'])
        trip_count_df = trip_count_df[trip_count_df['trip_count'] > 0]  # Exclude dates with no service

        # Find the date with the minimum number of trips
        min_trips_date = trip_count_df['trip_count'].idxmin()
        min_trips_count = trip_count_df.loc[min_trips_date, 'trip_count']

        # Create the plot
        fig = px.line(trip_count_df.reset_index(), x='index', y='trip_count', 
                    title=f'Trip Counts for Route {route_id}')

        result = {
            'answer': {
                'date': min_trips_date,
                'trip_count': min_trips_count
            },
            'additional_info': f"This analysis covered the period from {start_date} to {end_date}. The route analyzed was {route_id}.",
            'plot': fig  # This is a plotly Figure object
        }
        ```

        This code identifies the date with the fewest trips for the specified route, provides the trip count for that date, and creates a line plot showing how the number of trips varies over time. The additional information includes the date range of the analysis and the route ID that was analyzed.

example_6:
    question: Find the distance along the TEAL route from Orchard Downs South Shelter to Illini Union
    answer: |
        ```python
        import pandas as pd
        from thefuzz import process, fuzz

        # Find the TEAL route from all potential fields route_id, route_short_name and route_long_name
        possible_teal_matches = pd.concat([feed.routes['route_id'], feed.routes['route_short_name'], feed.routes['route_long_name']])
        teal_route_index = process.extractOne("TEAL", possible_teal_matches, scorer=fuzz.ratio)[2]
        teal_route_id = feed.routes.iloc[teal_route_index]['route_id']

        # Get trips for the TEAL route and their stop times along with stop names
        teal_trips = feed.trips[feed.trips['route_id'] == teal_route_id]
        teal_stop_times = feed.stop_times[feed.stop_times['trip_id'].isin(teal_trips['trip_id'])]
        teal_stop_times_with_names = pd.merge(teal_stop_times, feed.stops, on='stop_id')

        # Find the stop IDs for our two stops
        start_stop = process.extractOne("Orchard Downs South Shelter", teal_stop_times_with_names['stop_name'], scorer=fuzz.ratio)[0]
        end_stop = process.extractOne("Illini Union", teal_stop_times_with_names['stop_name'], scorer=fuzz.ratio)[0]

        start_stop_id = feed.stops[feed.stops['stop_name'] == start_stop]['stop_id'].iloc[0]
        end_stop_id = feed.stops[feed.stops['stop_name'] == end_stop]['stop_id'].iloc[0]

        # Get stop times for TEAL trips
        teal_stop_times = feed.stop_times[feed.stop_times['trip_id'].isin(teal_trips['trip_id'])]

        # Find a trip that includes both stops
        valid_trips = teal_stop_times[teal_stop_times['stop_id'].isin([start_stop_id, end_stop_id])].groupby('trip_id').filter(lambda x: len(x) >= 2)
        if valid_trips.empty:
            result = {
                'answer': None,
                'additional_info': "No trip found that includes both stops. They might be on different variations of the route."
            }
        else:
            # Take the first valid trip
            sample_trip_id = valid_trips['trip_id'].iloc[0]
            trip_stops = teal_stop_times[teal_stop_times['trip_id'] == sample_trip_id].sort_values('stop_sequence')

            # Get the shape for this trip
            shape_id = teal_trips[teal_trips['trip_id'] == sample_trip_id]['shape_id'].iloc[0]
            shape_points = feed.shapes[feed.shapes['shape_id'] == shape_id].sort_values('shape_pt_sequence')

            # Find the shape distances for our stops
            start_dist = trip_stops[trip_stops['stop_id'] == start_stop_id]['shape_dist_traveled'].iloc[0]
            end_dist = trip_stops[trip_stops['stop_id'] == end_stop_id]['shape_dist_traveled'].iloc[0]

            # Calculate the distance
            distance = abs(end_dist - start_dist)

            result = {
                'answer': distance,
                'additional_info': f"The distance is calculated along the TEAL route from '{start_stop}' to '{end_stop}'. "
                                f"This is based on the shape of trip {sample_trip_id}. "
                                f"Note that the actual distance might vary slightly between different trips of the same route."
            }

        # If we have geographical coordinates, we can create a map
        if not result['answer'] is None and 'shape_pt_lat' in feed.shapes.columns and 'shape_pt_lon' in feed.shapes.columns:
            import folium

            # Create a map centered on the route
            center_lat = shape_points['shape_pt_lat'].mean()
            center_lon = shape_points['shape_pt_lon'].mean()
            m = folium.Map(location=[center_lat, center_lon], zoom_start=13, tiles='CartoDB positron')

            # Add the route to the map
            route_coords = shape_points[['shape_pt_lat', 'shape_pt_lon']].values.tolist()
            folium.PolyLine(route_coords, weight=2, color='blue', opacity=0.8).add_to(m)

            # Add markers for the start and end stops
            start_stop_coords = feed.stops[feed.stops['stop_id'] == start_stop_id][['stop_lat', 'stop_lon']].iloc[0]
            end_stop_coords = feed.stops[feed.stops['stop_id'] == end_stop_id][['stop_lat', 'stop_lon']].iloc[0]

            folium.Marker(
                location=[start_stop_coords['stop_lat'], start_stop_coords['stop_lon']],
                popup=start_stop,
                icon=folium.Icon(color='green', icon='info-sign')
            ).add_to(m)

            folium.Marker(
                location=[end_stop_coords['stop_lat'], end_stop_coords['stop_lon']],
                popup=end_stop,
                icon=folium.Icon(color='red', icon='info-sign')
            ).add_to(m)

            result['map'] = m
        ```

example_7:
    question: Find directions from Orchard Downs to Newmark now
    answer: |
        import pandas as pd
        import numpy as np
        from datetime import datetime, time
        from thefuzz import process, fuzz
        import folium
        from geopy.geocoders import Nominatim
        from geopy.distance import geodesic

        geolocator = Nominatim(user_agent="gtfs2code")

        def geocode_location(location_name):
            try:
                location = geolocator.geocode(f"{location_name}, Champaign, IL, USA")
                return (location.latitude, location.longitude) if location else None
            except:
                return None


        def find_nearest_stops(lat, lon, stops_df, num_stops=5):
            stops_df["distance"] = stops_df.apply(
                lambda row: geodesic((lat, lon), (row["stop_lat"], row["stop_lon"])).meters,
                axis=1,
            )
            return stops_df.nsmallest(num_stops, "distance")

        def time_to_gtfs_format(t):
            hours, remainder = divmod(int(t), 3600)
            minutes, seconds = divmod(remainder, 60)
            departure_time =  f"{hours:02d}:{minutes:02d}:{seconds:02d}"
            return departure_time

        # Geocode the locations
        orchard_downs_coords = geocode_location("Orchard Downs")
        newmark_coords = geocode_location("Newmark")

        if not orchard_downs_coords or not newmark_coords:
            result = {
                "answer": "Unable to geocode one or both locations.",
                "additional_info": "Please check the location names and try again.",
            }
        else:
            # Find nearest stops
            orchard_downs_stops = find_nearest_stops(
                orchard_downs_coords[0], orchard_downs_coords[1], feed.stops
            )
            newmark_stops = find_nearest_stops(newmark_coords[0], newmark_coords[1], feed.stops)

            # Get current time (assume it's now)
            now = datetime.now()
            current_time = now.time().strftime("%H:%M:%S")
            h, m, s = current_time.split(":")
            current_time_seconds = 60 * 60 * int(h) + 60 * int(m) + int(s)
            current_day = now.strftime("%A").lower()

            # Find active services for the current day
            active_services = feed.calendar[
                (feed.calendar["start_date"] <= now.date())
                & (feed.calendar["end_date"] >= now.date())
                & (feed.calendar[current_day] == 1)
            ]["service_id"].tolist()

            # Find trips that serve both stops
            possible_trips = []
            for start_stop in orchard_downs_stops.itertuples():
                for end_stop in newmark_stops.itertuples():
                    trips_serving_start = set(
                        feed.stop_times[feed.stop_times["stop_id"] == start_stop.stop_id][
                            "trip_id"
                        ]
                    )
                    trips_serving_end = set(
                        feed.stop_times[feed.stop_times["stop_id"] == end_stop.stop_id][
                            "trip_id"
                        ]
                    )
                    common_trips = trips_serving_start.intersection(trips_serving_end)

                    for trip_id in common_trips:
                        trip = feed.trips[feed.trips["trip_id"] == trip_id].iloc[0]
                        if trip["service_id"] in active_services:
                            trip_stops = feed.stop_times[
                                (feed.stop_times["trip_id"] == trip_id)
                                & (
                                    feed.stop_times["stop_id"].isin(
                                        [start_stop.stop_id, end_stop.stop_id]
                                    )
                                )
                            ].sort_values("stop_sequence")
                            # Filter trips that depart in future and within 1 hour
                            trip_stops = trip_stops[trip_stops["departure_time"] > current_time_seconds]
                            trip_stops = trip_stops[trip_stops["departure_time"] < current_time_seconds + 3600]
                            if len(trip_stops) == 2:
                                start_time = trip_stops.iloc[0]["departure_time"]
                                end_time = trip_stops.iloc[1]["arrival_time"]
                                travel_time = end_time - start_time
                                if travel_time > 0 :
                                    possible_trip = {
                                        "trip": trip,
                                        "start_stop": start_stop,
                                        "end_stop": end_stop,
                                        "start_time": time_to_gtfs_format(start_time),
                                        "end_time": time_to_gtfs_format(end_time),
                                        "travel_time": travel_time,
                                    }
                                    possible_trips.append(possible_trip)
                                    
            shortest_travel_time = float("inf")
            if possible_trips:
                possible_trips_df = pd.DataFrame(possible_trips)
                possible_trips_df = possible_trips_df.sort_values("start_time").reset_index()
                options = []
                for i, trip in possible_trips_df.iterrows():
                    route = feed.routes[
                        feed.routes["route_id"] == trip["trip"]["route_id"]
                    ].iloc[0]
                    route_name = (
                        route["route_long_name"]
                        if pd.notna(route["route_long_name"])
                        else route["route_short_name"]
                    )
                    option = f"Take the {route_name} from {trip['start_stop'].stop_name} at {trip['start_time']} to {trip['end_stop'].stop_name}, arriving at {trip['end_time']}."
                    options.append(option)
                    if trip['travel_time'] < shortest_travel_time:
                        best_trip = trip
                        shortest_travel_time = trip['travel_time']
                        
                result = {
                    "answer":options ,
                    "additional_info": f"Best trip ID is {best_trip['trip']['trip_id']}. Travel time is approximately {best_trip['travel_time']/60:.2f} minutes. "
                    f"Walk to {best_trip['start_stop'].stop_name} to start your journey, and from {best_trip['end_stop'].stop_name} to reach your final destination.",
                }
            else:
                result = {
                    "answer": "No direct route found between the nearest stops to Orchard Downs and Newmark.",
                    "additional_info": "You might need to transfer between routes. Consider using a trip planner for more complex journeys.",
                }


# example_6:
#     question: Map all routes that pass through Illinois Terminal
#     answer: |
#         To map all routes that pass through Illinois Terminal, we can follow these steps:
#         ```python
#         import pandas as pd
#         import geopandas as gpd
#         import folium
#         from shapely.geometry import LineString

#         # Step 1: Identify the stop ID for Illinois Terminal
#         illinois_terminal = feed.stops[feed.stops['stop_name'].str.contains('Illinois Terminal', case=False, na=False)]
#         if illinois_terminal.empty:
#             result = {
#                 'answer': None,
#                 'additional_info': "Illinois Terminal stop not found in the GTFS data."
#             }
#         else:
#             illinois_terminal_ids = illinois_terminal['stop_id']

#             # Step 2: Find all trips that pass through this stop
#             trips_through_terminal = feed.stop_times[feed.stop_times['stop_id'].isin(illinois_terminal_ids)]['trip_id'].unique()

#             # Step 3: Identify the unique routes these trips belong to
#             routes_through_terminal = feed.trips[feed.trips['trip_id'].isin(trips_through_terminal)]['route_id'].unique()

#             # Step 4: Get the shapes for these routes
#             shapes_through_terminal = feed.trips[feed.trips['route_id'].isin(routes_through_terminal)]['shape_id'].unique()

#             # Create a GeoDataFrame with the shapes
#             shapes_gdf = feed.shapes[feed.shapes['shape_id'].isin(shapes_through_terminal)].copy()
#             shapes_gdf['geometry'] = shapes_gdf.apply(lambda row: (row['shape_pt_lon'], row['shape_pt_lat']), axis=1)
#             shapes_gdf = shapes_gdf.groupby('shape_id').agg({'geometry': lambda x: LineString(x.tolist())})
#             shapes_gdf = gpd.GeoDataFrame(shapes_gdf, geometry='geometry', crs="EPSG:4326")
#             shapes_gdf = shapes_gdf.reset_index().merge(feed.trips[['shape_id', 'route_id']], on='shape_id', how='left')

#             # Step 5: Create a map with all these routes
#             m = folium.Map(location=[illinois_terminal.iloc[0]['stop_lat'], illinois_terminal.iloc[0]['stop_lon']], 
#                         zoom_start=12, tiles='CartoDB positron')

#             # Add routes to the map
#             shapes_gdf.explore(
#                 column="route_id",
#                 m=m,
#                 legend=True,
#                 legend_kwds={"label": "Route ID"},
#                 name="Routes",
#                 tooltip=["route_id"],
#                 style_kwds={"weight": 2, "opacity": 0.7}
#             )

#             # Add Illinois Terminal marker
#             folium.Marker(
#                 [illinois_terminal.iloc[0]['stop_lat'], illinois_terminal.iloc[0]['stop_lon']],
#                 popup='Illinois Terminal',
#                 icon=folium.Icon(color='red', icon='info-sign')
#             ).add_to(m)

#             # Fit the map bounds to the shapes
#             m.fit_bounds(shapes_gdf.total_bounds.tolist())

#             # Add layer control
#             folium.LayerControl().add_to(m)

#             result = {
#                 'answer': f"{len(routes_through_terminal)} routes pass through Illinois Terminal.",
#                 'additional_info': f"These routes use {len(shapes_through_terminal)} unique shapes.",
#                 'map': m
#             }
#         ```

# example_7:
#     question: Find the next five departures from a specific stop
#     answer: |
#         To find the next five departures from a specific stop, we can follow these steps:

#         1. Identify the stop ID for the specified stop.
#         2. Get the current date, day of the week, and time.
#         3. Determine the service IDs that are active on the current date. Consider any exceptions to the regular service schedule for the current date.
#         4. Find the next five departures by filtering stop times based on the current time.

#         This approach allows us to provide real-time information about upcoming departures from the stop, which can be valuable for passengers and service planning.

#         Here's the code to implement this analysis:

#         ```python
#         from datetime import datetime, timedelta
#         import pandas as pd

#         # Step 1: Identify the stop ID for Illinois Terminal
#         illinois_terminal = feed.stops[feed.stops['stop_name'].str.contains('Illinois Terminal', case=False, na=False)]
#         if illinois_terminal.empty:
#             result = {
#                 'answer': None,
#                 'additional_info': "Illinois Terminal stop not found in the GTFS data."
#             }


#         # Step 2: Get current date, day of the week and time
#         datetime_now = datetime.now()
#         today = datetime_now.date()
#         current_time = datetime_now.time().strftime("%H:%M:%S")
#         h, m, s = current_time.split(':')
#         current_time_seconds = 60*60*int(h) + 60*int(m) + int(s)
#         day_of_week = today.strftime("%A").lower()

#         service_ids = feed.calendar[
#             (feed.calendar["start_date"] <= today)
#             & (feed.calendar["end_date"] >= today)
#             & (feed.calendar[day_of_week] == 1)
#         ]["service_id"].unique()

#         # Step 3: Get current service IDs considering exceptions
#         date_exceptions = feed.calendar_dates[feed.calendar_dates["date"] == today]
#         added_service_ids = date_exceptions[date_exceptions["exception_type"] == 1]["service_id"].unique()
#         removed_service_ids = date_exceptions[date_exceptions["exception_type"] == 2]["service_id"].unique()
#         final_service_ids = list(set(service_ids) | set(added_service_ids) - set(removed_service_ids))

#         # Step 4: Find the next five departures by filtering stop times
#         trips_today = feed.trips[feed.trips["service_id"].isin(final_service_ids)]
#         trips_today = trips_today.merge(feed.routes, on="route_id")
#         stop_times_merged = feed.stop_times.merge(trips_today[["trip_id","route_id","direction_id","route_long_name","trip_headsign"]], on="trip_id")
#         stop_times_today = stop_times_merged[stop_times_merged["trip_id"].isin(trips_today["trip_id"])]
#         future_stop_times = stop_times_today[stop_times_today["departure_time"] >= current_time_seconds]
#         stop_times_terminal = future_stop_times[future_stop_times["stop_id"].isin(illinois_terminal["stop_id"])]
#         stop_times_terminal = stop_times_terminal.sort_values("departure_time")

#         result_data = []
#         for _, departure in stop_times_terminal.head(5).iterrows():
#             departure_time = int(departure["departure_time"])
#             hours, remainder = divmod(departure_time, 3600)
#             minutes, seconds = divmod(remainder, 60)
            
#             # Format as HH:MM:SS
#             departure_time =  f"{hours:02d}:{minutes:02d}:{seconds:02d}"
#             result_data.append({
#                 "route_id":departure['route_id'],
#                 "departure_time": departure_time,
#                 "route_name": departure["route_long_name"],
#                 "trip_headsign": departure["trip_headsign"],
#                 "direction_id": departure["direction_id"]
#             })
            
#         result = {
#                 'answer': result_data,
#                 'additional_info': f"These are the next 5 buses leaving from Illinois Terminal (Stop ID: {illinois_terminal.stop_id.to_list()}) after {current_time}."
#             }
#         ```

# example_8:
#     question: Find the most common transfer locations between routes
#     answer: |
#         ```python
#         from datetime import date

#         # Get today's date
#         today = date.today()
#         day_of_week = today.strftime("%A").lower()

#         # Find all routes with GREEN in their name or ID
#         green_routes = feed.routes[
#             feed.routes['route_id'].str.contains('GREEN', case=False, na=False) |
#             feed.routes['route_short_name'].str.contains('GREEN', case=False, na=False) |
#             feed.routes['route_long_name'].str.contains('GREEN', case=False, na=False)
#         ]

#         if green_routes.empty:
#             result = {
#                 'answer': None,
#                 'additional_info': "No routes found with 'GREEN' in their name or ID."
#             }
#         else:
#             green_routes_info = []

#             for _, route in green_routes.iterrows():
#                 route_id = route['route_id']

#                 # Get all service_ids associated with this GREEN route
#                 route_services = feed.trips[feed.trips['route_id'] == route_id]['service_id'].unique()

#                 # Check the calendar for regular services
#                 regular_services = set(feed.calendar[
#                     (feed.calendar['start_date'] <= today) &
#                     (feed.calendar['end_date'] >= today) &
#                     (feed.calendar[day_of_week] == 1) &
#                     (feed.calendar['service_id'].isin(route_services))
#                 ]['service_id'])

#                 # Check calendar_dates for exceptions
#                 if hasattr(feed, 'calendar_dates'):
#                     exceptions = feed.calendar_dates[
#                         (feed.calendar_dates['date'] == today) &
#                         (feed.calendar_dates['service_id'].isin(route_services))
#                     ]
#                     added_services = set(exceptions[exceptions['exception_type'] == 1]['service_id'])
#                     removed_services = set(exceptions[exceptions['exception_type'] == 2]['service_id'])
#                 else:
#                     added_services = set()
#                     removed_services = set()

#                 # Combine regular services and exceptions
#                 operational_services = (regular_services | added_services) - removed_services

#                 is_operational = len(operational_services) > 0

#                 # Get trip count if operational
#                 if is_operational:
#                     trip_count = feed.trips[
#                         (feed.trips['route_id'] == route_id) &
#                         (feed.trips['service_id'].isin(operational_services))
#                     ].shape[0]
#                 else:
#                     trip_count = 0

#                 green_routes_info.append({
#                     'route_id': route_id,
#                     'route_short_name': route['route_short_name'],
#                     'route_long_name': route['route_long_name'],
#                     'is_operational': is_operational,
#                     'trip_count': trip_count
#                 })

#             result = {
#                 'answer': green_routes_info,
#                 'additional_info': f"Found {len(green_routes_info)} routes with 'GREEN' in their name or ID. "
#                                 f"Today is {today}, a {day_of_week.capitalize()}."
#             }
#         ```
